# Streaming Transcription Plan

**Author:** VoiceMark Team  
**Created:** 2025-01-XX  
**Status:** âœ… **Implemented** (Updated 2025-01-04)

## Overview

~~Currently VoiceMark uses a **batch transcription** model~~

**UPDATE:** VoiceMark now supports both **batch** and **streaming** transcription modes:

1. **Recording ASR (batch with incremental partials)** - Default mode for reliability
   - Audio accumulates in 1-second chunks
   - Partial results emitted every 3 seconds during recording
   - Final transcription when recording stops
   
2. **Streaming ASR (real-time WebSocket)** - Available via `VITE_ASR_MODE=streaming`
   - Real-time PCM audio streaming via WebSocket
   - Continuous partial results while speaking
   - Lower latency, higher resource usage

**Recent Improvements (2025-01-04):**
- âœ… Implemented incremental processing in `recordingAsr.ts`
- âœ… Real-time partial results during recording
- âœ… Graceful handling of abrupt stops with data preservation
- âœ… Optimized Whisper parameters for lower latency
- âœ… Comprehensive test coverage for incremental processing

---

## Current Architecture (Updated 2025-01-04)

### Recording ASR with Incremental Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Frontend        â”‚         â”‚      Sidecar        â”‚
â”‚                     â”‚         â”‚                     â”‚
â”‚ MediaRecorder       â”‚         â”‚  Rust + axum        â”‚
â”‚    â†“ (1s chunks)    â”‚         â”‚                     â”‚
â”‚ Buffer + Process    â”‚   â”€â”€â†’   â”‚  POST /transcribe   â”‚
â”‚    â†“ (every 3s)     â”‚ (batch) â”‚    â†“                â”‚
â”‚ asr:partial  â†â”€â”€â”€â”€â”€â”€â”‚   â†â”€â”€   â”‚  whisper-rs         â”‚
â”‚ asr:final (on stop) â”‚         â”‚  (optimized params) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Recording ASR Flow
1. `recordingAsr.ts` captures audio in 1-second chunks via `MediaRecorder`
2. Chunks accumulate in memory buffer (`audioChunks[]`)
3. **Every 3 seconds:** Accumulated audio transcribed â†’ `asr:partial` event emitted
4. **On stop:** All chunks finalized â†’ single POST to `/transcribe` â†’ `asr:final` event
5. Graceful handling: If stopped during processing, buffer is preserved and finalized

### Streaming ASR Architecture (via WebSocket)

### Streaming ASR Architecture (via WebSocket)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  WS     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Frontend        â”‚   â†“â†‘    â”‚      Sidecar        â”‚
â”‚                     â”‚         â”‚                     â”‚
â”‚ AudioWorklet        â”‚ â”€â”€â”€â”€â”€â”€â†’ â”‚  WS /stream         â”‚
â”‚    â†“ (PCM chunks)   â”‚         â”‚    â†“                â”‚
â”‚                     â”‚   â†â”€â”€â”€â”€ â”‚  Whisper streaming  â”‚
â”‚ asr:partial events  â”‚         â”‚  (6s auto-commit)   â”‚
â”‚ asr:final event     â”‚         â”‚  (500ms throttle)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Status:** âœ… Fully implemented in `streamingAsr.ts` and `sidecar/src/stream.rs`

### Key Differences

| Feature | Recording ASR | Streaming ASR |
|---------|--------------|---------------|
| Audio Capture | MediaRecorder (WebM) | AudioWorklet (PCM) |
| Latency | 3-second intervals | ~500ms |
| Resource Usage | Lower | Higher |
| Data Loss Risk | Very Low (buffered) | Low (streaming) |
| Complexity | Simple | Complex |
| Use Case | Default, reliable | Real-time, low-latency |

---

## Latency Improvements (2025-01-04)

### Recording ASR
- **Before:** No feedback until stop (could be 30s+ wait)
- **After:** Partial results every 3 seconds, final on stop
- **User Experience:** See transcription progress while recording

### Streaming ASR
- **Already had:** Real-time partials every 500ms
- **Improvements:** Better buffering, no data loss on disconnect

### Whisper Optimizations
Applied to both modes:
- `set_max_len(1)` - Smaller token segments for faster processing
- `set_speed_up(true)` - Enable Whisper speed optimizations
- `set_single_segment(false)` - Allow incremental output
- `set_audio_ctx(0)` - Use default context window

---

## Implementation Status

### âœ… Completed (Phases 1-5)

#### Phase 1: WebSocket Infrastructure (2024)
- âœ… WebSocket endpoint `/stream` in sidecar
- âœ… Protocol for audio/partial/final messages
- âœ… Frontend WebSocket client in `streamingAsr.ts`

#### Phase 2: Audio Pipeline (2024)
- âœ… AudioWorklet for PCM capture in `pcmAudioProcessor.worklet.ts`
- âœ… Audio resampling to 16kHz mono
- âœ… Frontend audio buffering (500ms chunks)

#### Phase 3: Whisper Streaming (2024)
- âœ… Sliding window transcription in `sidecar/src/stream.rs`
- âœ… 6-second auto-commit, 500ms partial throttle

#### Phase 4: Frontend Integration (2024)
- âœ… ASR events handling for partials/finals
- âœ… Smooth UI transitions
- âœ… Mode selection via `VITE_ASR_MODE`

#### Phase 5: Recording ASR Improvements (2025-01-04)
- âœ… Incremental processing during recording
- âœ… Partial emission every 3 seconds
- âœ… Graceful stop with data preservation
- âœ… Whisper parameter optimization
- âœ… Race condition fixes
- âœ… Comprehensive test coverage (8 integration tests)

### ğŸ“ Files Modified

#### Sidecar (Rust)
- âœ… `sidecar/src/stream.rs` - WebSocket handler
- âœ… `sidecar/src/transcribe.rs` - Optimized parameters (2025-01-04)

#### Frontend (TypeScript)
- âœ… `src/asr/streamingAsr.ts` - WebSocket client
- âœ… `src/asr/pcmAudioProcessor.worklet.ts` - PCM capture
- âœ… `src/asr/recordingAsr.ts` - Incremental processing (2025-01-04)
- âœ… `src/asr/recordingAsr.incremental.test.ts` - Tests (2025-01-04)
- âœ… `eslint.config.js` - Linter config (2025-01-04)

---

## Implementation Options

### Option A: Whisper.cpp Real-Time (Recommended)

**Whisper.cpp** has experimental real-time streaming support:
- `stream` example in whisper.cpp repo
- Uses Voice Activity Detection (VAD)
- Processes audio in overlapping windows

**Pros:**
- Stay in Rust ecosystem (faster, single binary)
- whisper-rs already integrated
- Lower resource usage than Python

**Cons:**
- Streaming is still experimental in whisper.cpp
- May need to update whisper-rs bindings
- Less documentation than Python alternatives

**Effort:** 3-5 days

### Option B: Faster-Whisper Python Sidecar

Replace Rust sidecar with Python using `faster-whisper` library:
- GPU support via CTranslate2
- Better streaming support
- Larger community

**Pros:**
- More mature streaming examples
- GPU acceleration if CUDA available
- Easier to experiment with

**Cons:**
- Python runtime dependency
- More memory usage
- Deployment complexity

**Effort:** 5-8 days

### Option C: Hybrid (Both Sidecars)

Keep Rust sidecar for batch, add Python for streaming:
- User can choose based on hardware
- Fallback if one fails

**Pros:**
- Flexibility
- Gradual migration path

**Cons:**
- Two codebases to maintain
- Configuration complexity

**Effort:** 8-12 days

---

## Recommended Approach: Option A (Whisper.cpp Streaming)

Given the existing Rust investment and VoiceMark's offline-first focus, we should enhance the current sidecar.

### Phase 1: WebSocket Infrastructure (1-2 days)

1. **Add WebSocket endpoint to sidecar**
   ```rust
   // main.rs
   .route("/stream", get(ws_handler))
   ```

2. **Define WebSocket protocol**
   ```json
   // Client â†’ Server: Audio chunk
   { "type": "audio", "data": "<base64 PCM>", "sample_rate": 16000 }
   
   // Server â†’ Client: Partial result
   { "type": "partial", "text": "hello wor", "ts": 1234567890 }
   
   // Server â†’ Client: Final result  
   { "type": "final", "text": "hello world", "ts": 1234567890 }
   
   // Client â†’ Server: End of stream
   { "type": "end" }
   ```

3. **Frontend WebSocket client**
   ```typescript
   // streamingAsr.ts
   const ws = new WebSocket('ws://localhost:3001/stream');
   ws.onmessage = (e) => {
     const msg = JSON.parse(e.data);
     if (msg.type === 'partial') emit({ type: 'asr:partial', text: msg.text });
     if (msg.type === 'final') emit({ type: 'asr:final', text: msg.text });
   };
   ```

### Phase 2: Audio Pipeline (1-2 days)

1. **Replace MediaRecorder with AudioWorklet**
   - Direct access to PCM samples
   - Lower latency than MediaRecorder
   - No codec overhead

2. **Audio resampling in browser**
   - Convert to 16kHz mono
   - Send raw PCM (no WebM container)

3. **Frontend audio buffering**
   ```typescript
   // Collect 500ms of audio, send to WebSocket
   const CHUNK_SIZE = 16000 * 0.5; // 8000 samples = 500ms
   ```

### Phase 3: Whisper Streaming (2-3 days)

1. **Investigate whisper-rs streaming API**
   - Check if `whisper-rs` exposes streaming/partial
   - May need to use lower-level whisper.cpp bindings

2. **Sliding window transcription**
   ```
   Audio buffer: [====|====|====|====]
                      â†‘
                 Current position
   
   - Keep last 10-30s of audio
   - Re-transcribe with context on each chunk
   - Emit partial after each chunk
   - Emit final when "end" received
   ```

3. **Confidence thresholding**
   - Low confidence â†’ partial (grayed text)
   - High confidence â†’ final (committed text)

### Phase 4: Frontend Integration (1 day)

1. **Update ASR events handling**
   - Partials update transcript panel (grayed)
   - Finals commit to editor
   - Smooth transition between partial/final

2. **Fallback to batch mode**
   - If WebSocket fails, use existing POST `/transcribe`
   - Configuration toggle for user preference

---

## Detailed Implementation Plan

### Week 1: WebSocket + Audio Pipeline

| Day | Task | Deliverable |
|-----|------|-------------|
| 1 | Add WebSocket endpoint to sidecar | `/stream` accepts connections |
| 2 | AudioWorklet for PCM capture | Raw audio in browser |
| 3 | Wire WS client to AudioWorklet | Audio flows to sidecar |
| 4 | Test round-trip (echo audio back) | End-to-end verified |

### Week 2: Whisper Integration

| Day | Task | Deliverable |
|-----|------|-------------|
| 5 | Research whisper-rs streaming | Document findings |
| 6 | Implement sliding window buffer | Audio accumulation |
| 7 | Periodic re-transcription | Partials returned |
| 8 | Final transcription on end | Complete result |
| 9 | Frontend partial display | Text appears while speaking |
| 10 | Testing + bug fixes | Stable streaming |

---

## Technical Decisions (Finalized)

### 1. Chunk Size / Latency Tradeoff âœ…

**Recording ASR:** 1000ms MediaRecorder chunks, 3000ms processing interval  
**Streaming ASR:** 500ms PCM chunks, 500ms throttle

### 2. Context Window âœ…

**Streaming ASR:** 6-second auto-commit maintains sufficient context  
**Recording ASR:** Full context preserved (all chunks used for transcription)

### 3. Partial Emission Strategy âœ…

**Recording ASR:** Fixed 3-second interval  
**Streaming ASR:** Throttled to 500ms minimum

### 4. WebSocket vs Server-Sent Events âœ…

**Decision:** WebSocket (bidirectional for audio upload)

---

## Success Criteria âœ…

1. âœ… **Text appears within 1-3 seconds** of speaking (depending on mode)
2. âœ… **No UI jank** during continuous dictation
3. âœ… **Final accuracy** maintained with optimization
4. âœ… **CPU usage** reasonable with optimized parameters
5. âœ… **Fallback works** (recordingAsr as default, streaming optional)
6. âœ… **Data preservation** on abrupt stops

---

## Next Steps

1. âœ… ~~Create this plan document~~
2. âœ… ~~Review and approve approach~~
3. âœ… ~~Begin implementation~~
4. âœ… ~~Complete Phase 1-4 (WebSocket streaming)~~
5. âœ… ~~Complete Phase 5 (Recording ASR improvements)~~
6. ğŸ”„ **Monitor performance in production use**
7. ğŸ”„ **Gather user feedback on latency/accuracy tradeoffs**
8. â¬œ **Future: Voice Activity Detection (VAD) for smarter partial emission**
9. â¬œ **Future: GPU acceleration investigation**

---

### 3. Partial Emission Strategy

When to emit partial results?

- **After each chunk:** Most responsive, flickery
- **On silence detection:** Natural pauses
- **Fixed interval:** Predictable (every 1s)

**Recommendation:** Fixed 1-second interval with VAD enhancement later.

### 4. WebSocket vs Server-Sent Events

| Approach | Pros | Cons |
|----------|------|------|
| WebSocket | Bidirectional, real-time | More complex |
| SSE | Simpler, one-way | Can't send audio up |

**Decision:** WebSocket (we need bidirectional for audio upload).

---

## Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| whisper-rs lacks streaming API | High | Use raw whisper.cpp bindings or Python fallback |
| High CPU during streaming | Medium | Limit re-transcription frequency |
| Audio quality degradation | Medium | Test with various microphones |
| Browser AudioWorklet support | Low | Fallback to MediaRecorder chunks |

---

## Success Criteria

1. **Text appears within 1.5 seconds** of speaking
2. **No UI jank** during continuous dictation
3. **Final accuracy** matches or exceeds batch mode
4. **CPU usage** stays under 100% on target hardware (GTX 750 Ti / i5)
5. **Fallback works** if streaming fails

---

---

## References

- [whisper.cpp stream example](https://github.com/ggerganov/whisper.cpp/tree/master/examples/stream)
- [AudioWorklet API](https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet)
- [tokio-tungstenite](https://github.com/snapview/tokio-tungstenite)
- [whisper-rs](https://github.com/tazz4843/whisper-rs)
- [faster-whisper](https://github.com/guillaumekln/faster-whisper)

---

## Summary

VoiceMark now provides two transcription modes:

1. **Recording ASR (Default)** - Reliable batch processing with incremental partials every 3 seconds
2. **Streaming ASR** - Real-time WebSocket streaming with ~500ms latency

Both modes feature:
- Optimized Whisper parameters for lower latency
- Graceful error handling
- Data preservation on interruption
- Comprehensive test coverage

The incremental improvements to Recording ASR (2025-01-04) bridge the gap between batch and streaming modes, providing real-time feedback without the complexity of WebSocket connections.
